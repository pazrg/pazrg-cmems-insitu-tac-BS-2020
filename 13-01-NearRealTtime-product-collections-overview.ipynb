{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![header](https://i.imgur.com/I4ake6d.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN SITU BLACK SEA TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><i> 13-01-Part-one-out-of-five </i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An overview of  the BS `NRT` product/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction\">Introduction</a></span></li>\n",
    "        <li>\n",
    "            <span><a href=\"#Setup\" data-toc-modified-id=\"Setup\">Setup</a></span>\n",
    "            <ul>\n",
    "                <li><span><a href=\"#Python-packages\" data-toc-modified-id=\"Python-packages\">Python packages</a></span></li>\n",
    "                <li><span><a href=\"#Copernicus-Database\" data-toc-modified-id=\"Copernicus-Database\">Copernicus database</a></span></li>\n",
    "                <li><span><a href=\"#Auxiliary-functions\" data-toc-modified-id=\"Setup\">Auxiliary functions</a></span></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span><a href=\"#COLLECTION-OVERVIEW\" data-toc-modified-id=\"COLLECTION-OVERVIEW\">Collection overview</a></span>\n",
    "            <ul>\n",
    "                <li><span><a href=\"#Getting-started\" data-toc-modified-id=\"Getting-started-packages\">Getting started</a></span></li>\n",
    "                <li><span><a href=\"#Choosing-collection\" data-toc-modified-id=\"Chosing-collection\">Choosing collection</a></span></li>\n",
    "                <li>\n",
    "                    <span><a href=\"#Overview\" data-toc-modified-id=\"Overview\">Overview</a></span>\n",
    "                    <ul>\n",
    "                <li><span><a href=\"#Platforms\" data-toc-modified-id=\"Platforms\">Platforms</a></span></li>\n",
    "                <li><span><a href=\"#Feature-types\" data-toc-modified-id=\"Feature-types\">Feature (file types)</a></span></li>\n",
    "                <li><span><a href=\"#Source-types\" data-toc-modified-id=\"Source-types\">Source types (data types)</a></span></li>\n",
    "                <li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters\">Parameters</a></span></li>\n",
    "                <li><span><a href=\"#Providers\" data-toc-modified-id=\"Providers\">Providers</a></span></li>\n",
    "            </ul>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><span><a href=\"#Wrap-up\" data-toc-modified-id=\"Wrap-up\">Wrap-up</a></span></li>\n",
    "        <li><span><a href=\"#Next-tutorial\" data-toc-modified-id=\"Next-tutorial\">Next tutorial</a></span></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "This notebook focus on getting an overview of the files available in the different collections (`latest`, `monthly` and `history`) available within the In Situ Near Real Time product/dataset covering the Black Sea: `INSITU_BS_NRT_OBSERVATIONS_013_034`. Click [here](https://resources.marine.copernicus.eu/?option=com_csw&task=results?option=com_csw&view=details&product_id=INSITU_BS_NRT_OBSERVATIONS_013_034) to  view the dedicated section of this product within the [CMEMS Catalog]('http://marine.copernicus.eu/services-portfolio/access-to-products/')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any In Situ NRT product/dataset is just a bunch of netcdf files produced by the platforms (*drifters, profilers, gliders, moorings, HF-radars, vessels etc*) deployed in a certain seas (in this case, the Black Sea); so many files that navigation/subsetting can be challenging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ![BS.gif](img/BS.gif)| \n",
    "|:--:| \n",
    "| *GIF of the location (point or trajectory) of the platforms providing near real time data in the BS area since 1922* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To smooth the process of data discovery to users, the In Situ TAC provides a set of `index files` that describe the aforementioned file collections. In addition to these index files, it is also possible to find further info regarding each platform contributting with files on the `index_platform.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Index |  Description |\n",
    "| ------- | ----------- |\n",
    "| `index_latest.txt`  |  List of available files within the latest collection + metadata | \n",
    "| `index_monthly.txt`   | List of available files within the monthly collection + metadata |\n",
    "| `index_history.txt`   |  List of available files within the history collection + metadata |\n",
    "| `index_platform.txt`   | Full list of platforms + metadata |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check more about these files in the <a href=\"https://archimer.ifremer.fr/doc/00324/43494/\" target=\"_blank\">Product User Manual</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>OBJECTIVE</b>\n",
    "    \n",
    "***  \n",
    "To discover which platforms, file types, data types, parameters and providers are to be expected in a specific collection of the BS NRT product/dataset by using the aforementioned index files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the notebook to properly run we need to first load the next packages available from the Jupyter Notebook Ecosystem. Please run the `next cell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import IPython\n",
    "from shapely.geometry import box \n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import json2html\n",
    "from json2html import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    "    \n",
    "***  \n",
    "If any of them raises any error it means you need to install the module first. For doing so please:\n",
    "1. Open a new cell int he notebook\n",
    "2. Run <i>`!conda install packageName --yes`</i> or <i>`!conda install -c conda-forge packageName --yes`</i> or <i>`!pip install packageName`</i>\n",
    "3. Import again!\n",
    "<br><br>\n",
    "Example: <i>how-to-solve import error for json2html module </i>\n",
    "\n",
    "![region.png](img/errorImporting.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copernicus Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please `set next your CMEMS User credentials` in the next cell and `run the cell` afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr = 'inputHereYourCMEMSUser'\n",
    "pas = 'inputHereYourCMEMSPassword'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    "    \n",
    "***  \n",
    "**Don't you have credentials yet?** \n",
    "<br>Please go [here](https://resources.marine.copernicus.eu/?option=com_sla) to get the above credentials to be able to access CMEMS secured FTP servers hosting CMEMS data products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before, we will focus on the Near Real Time product/dataset covering the Black Sea so, please `run the next` to load the info defining such product/dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'host': 'nrt.cmems-du.eu',#ftp host => nrt.cmems-du.eu for Near Real Time products\n",
    "    'product': 'INSITU_BS_NRT_OBSERVATIONS_013_034',#name of the In Situ Near Real Time product in the BS area\n",
    "    'name': 'bs_multiparameter_nrt',#name of the dataset available in the above In Situ Near Real Time product\n",
    "    'index_files': ['index_latest.txt', 'index_monthly.txt', 'index_history.txt'],#files describing the content of the lastest, monthly and history netCDF file collections available withint he above dataset\n",
    "    'index_platform': 'index_platform.txt',#files describing the netwotk of platforms contributting with files in the abve collections\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "***  \n",
    "In case you want to explore any other In Situ NRT product/dataset just set the above definitions accordingly and you will be able to reproduce the analysis we will perform next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For exploring the product/dataset we will use a set of files called `index files` located in the CMEMS FTP server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Getting the links to the index files**.\n",
    "In order to get the links to download manualy the most updated version of these files we will use the next function. <br>Please `run the next cell` to load it in memory for later use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexFileLinks(usr,pas,dataset):\n",
    "    #Provides the link to download each index file from the ftp server\n",
    "    url = os.path.join('ftp://', dataset['host'],'Core',dataset['product'],dataset['name'])\n",
    "    indexes = dataset['index_files'] + [dataset['index_platform']]\n",
    "    for index in indexes:\n",
    "        index_url = os.path.join(url,index)\n",
    "        urlParsed = urlparse(index_url)\n",
    "        index_url = index_url.replace(urlParsed.netloc, usr + ':' + pas + '@' + urlParsed.netloc)\n",
    "        print('...Click and download '+index+' from:')\n",
    "        print(index_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Index files reader**.\n",
    "In order to load the information contained in *each* of the files we will use the next function. <br>Please `run the next cell` to load it in memory for later use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readIndexFileFromCWD(path2file):\n",
    "    #Load as pandas dataframe the file in the provided path\n",
    "    with open(path2file, 'rb') as f:\n",
    "        filename = os.path.basename(path2file)\n",
    "        print('...Loading info from: '+filename)\n",
    "        raw_index_info = pd.read_csv(path2file, skiprows=5)\n",
    "    return raw_index_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Index files merger**.\n",
    "In order to load the information contained in *all* the indexes in a one single entity we will use the next function. <br>Please `run the next cell` to load it in memory for later use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexFilesInfo(usr, pas, dataset):\n",
    "    # Load and merge in a single entity all the information contained on each file descriptor of a given dataset\n",
    "    # 1) Loading the index platform info as dataframe\n",
    "    path2file = os.path.join(os.path.join(os.path.join(os.getcwd(),'data'), 'index_files'), dataset['index_platform'])\n",
    "    indexPlatform = readIndexFileFromCWD(path2file)\n",
    "    indexPlatform.rename(columns={indexPlatform.columns[0]: \"platform_code\" }, inplace = True)\n",
    "    indexPlatform = indexPlatform.drop_duplicates(subset='platform_code', keep=\"first\")\n",
    "    # 2) Loading the index files info as dataframes\n",
    "    netcdf_collections = []\n",
    "    for filename in dataset['index_files']:\n",
    "        path2file = os.path.join(os.getcwd(),'data', 'index_files',filename)\n",
    "        indexFile = readIndexFileFromCWD(path2file)\n",
    "        netcdf_collections.append(indexFile)\n",
    "    netcdf_collections = pd.concat(netcdf_collections)\n",
    "    # 3) creating new columns: derived info\n",
    "    netcdf_collections['netcdf'] = netcdf_collections['file_name'].str.split('/').str[-1]\n",
    "    netcdf_collections['file_type'] = netcdf_collections['netcdf'].str.split('.').str[0].str.split('_').str[1]\n",
    "    netcdf_collections['data_type'] = netcdf_collections['netcdf'].str.split('.').str[0].str.split('_').str[2]\n",
    "    netcdf_collections['platform_code'] = netcdf_collections['netcdf'].str.split('.').str[0].str.split('_').str[3]\n",
    "    #4) Merging the information of all files\n",
    "    headers = ['platform_code','wmo_platform_code', 'institution_edmo_code', 'last_latitude_observation', 'last_longitude_observation','last_date_observation']\n",
    "    result = pd.merge(netcdf_collections,indexPlatform[headers],on='platform_code')\n",
    "    print('Ready!')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLLECTION OVERVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the analysis to be carried out we need the most recent version of the index files. In `/data/index_files` we have provided a copy but, **if you are running this notebook later than April 2020** please:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download again the index files.<br> `Run the next cell` to dicover the links to download the index files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getIndexFileLinks(usr,pas,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Upload to the `/data/index_files` folder the downloaded files. <br> `Run the next cell` to do it from this very same notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.IFrame('data/index_files', width='100%', height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load into a dataframe the info contained in such files: `run the next cell!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = getIndexFilesInfo(usr, pas, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run now the next cell` to see the information just loaded above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use all this information next to have an glimpse to the content of one of the product/dataset netCDF files collections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Set in the next cell the collection` you wanna get an overview of and `run it` afterwards. <br> We have selected the 'latest' by default but please feel free to change it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_collection = 'history'\n",
    "targeted_collection_info = info[info['file_name'].str.contains(targeted_collection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>IMPORTANT</b>\n",
    "\n",
    "***\n",
    "Please remember available options:\n",
    "<ul>\n",
    "    <li><i>latest</i>: daily files from platforms (last 30 days of data)</li>\n",
    "    <li><i>monthly</i>: monthly files from platforms (last 5 years of data)</li>\n",
    "    <li><i>history</i>: one file per platform (all platform data)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any Situ NRT products/datasets collections are composed by files reported by a network of platforms located in the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's `run the next cell` to know how many platforms are contributting to this product/dataset collection with files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(targeted_collection_info.groupby('platform_code').groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a closer look to this list of platforms: `run the next cells`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_platforms = [{\n",
    "    'code':code, \n",
    "    'provider(s)': files['institution_edmo_code'].iloc[0],\n",
    "    'files': {\n",
    "        'nfiles': len(files), \n",
    "        'feature(s)': [{'code': ftype, 'nfiles':len(files.groupby('file_type').get_group(ftype)),'sources(s)': [{'code': dtype, 'nfiles': len(files.groupby('file_type').get_group(ftype).groupby('data_type').get_group(dtype)), 'parameters': [param for param in sum([files.groupby('file_type').get_group(ftype).groupby('data_type').get_group(dtype)['parameters'].unique().tolist()],[])[0].split(' ') if '_' not in param and param not in ['DEPH', 'PRES'] and param != '']} for dtype in files[files['file_type']==ftype]['data_type'].unique().tolist()]} for ftype in files['file_type'].unique().tolist()]}\n",
    "} for code,files in targeted_collection_info.groupby(['platform_code'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.HTML(json2html.convert(data_platforms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too much info? Let's see one in particular! `Run the next cells`:\n",
    "<a id='platform_selected'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '7900596'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = [platform for platform in data_platforms if platform['code'] == code]\n",
    "IPython.display.HTML(json2html.convert(selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we can see that each platform:\n",
    "* Can have one or more providers - identified by a blank-separated-list of one or more codes: the so called *edmo code* (we will see more about this later).\n",
    "* Produces different type of files (see above `PR` *type* bigram) from one or more data sources (see above `PF` *source* bigram) and containing more or less parameters (see *parameters* codes). We will se next more about this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok but...where is it located? There are some geographical references that we can use to infer the location of the platform:\n",
    "* the bounding box of the produced files (this is, the spatial coverage - a rectangular simplification actually - of the data measured by the platform) \n",
    "* the last position reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw all them on a map to get an idea!: `run the next cell`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing map\n",
    "m = folium.Map(location=[39.0, 0], zoom_start=4)\n",
    "#Loooping over each file produced by the platform above\n",
    "for idx,file in targeted_collection_info[targeted_collection_info['platform_code'] == code].iterrows():\n",
    "    #Bounding-box of each file to map as polygon\n",
    "    upper_left = [file['geospatial_lat_max'], file['geospatial_lon_min']]\n",
    "    upper_right = [file['geospatial_lat_max'], file['geospatial_lon_max']]\n",
    "    lower_right = [file['geospatial_lat_min'], file['geospatial_lon_max']]\n",
    "    lower_left = [file['geospatial_lat_min'], file['geospatial_lon_min']]\n",
    "    edges = [upper_left, upper_right, lower_right, lower_left]\n",
    "    m.add_child(folium.vector_layers.Polygon(locations=edges, popup='file bbox: '+file['netcdf']))\n",
    "#Last reported position to map as marker\n",
    "m.add_child(folium.Marker([file['last_latitude_observation'], file['last_longitude_observation']], popup=file['platform_code']+' last position' ))\n",
    "#Zooming closer\n",
    "m.fit_bounds(edges, max_zoom=6)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the next tutorial we will see how to use this very same geographical info to select only those files covering a specific area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING</b>\n",
    "    \n",
    "***  \n",
    "**Don't you see the map?** Please open the notebook in a different browser (i.e Chrome!) as some have problems rendering folium maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b style=\"margin-right: 2em\">IMPORTANT</b>\n",
    "    \n",
    "*** \n",
    "**Are you a provider?**\n",
    "If you have a platform (or know about one) producing data in the area and it does not appear ont he list please **contact us** by emailing the corresponding Regional CMEMS In Situ TAC Service Desk [here](http://www.marineinsitu.eu/submit-data/) **or let the speaker know**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Data sources` represents the elements that report oceanographic data. <br>So far the In Situ TAC distinguishes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| code | description |\n",
    "| ------- | ------- |\n",
    "|BO | Bottle |\n",
    "|BA | Data from Bathy messages on GTS |\n",
    "|DB | Drifting buoys |\n",
    "|DC | Drifting buoy reporting calculated sea water current |\n",
    "|FB | FerryBox |\n",
    "|MO | Fixed buoys or mooring time series |\n",
    "|TG | Tide gauges |\n",
    "|GL | Gliders |\n",
    "|ML | Mini logger |\n",
    "|CT | Oceanographic CTD profiles | //historic index file el data_type es \"oceanographic CTD profiles\"\n",
    "|PF | Profiling floats vertical profiles |\n",
    "|RE | Recopesca |\n",
    "|RF | River flows |\n",
    "|SF | Scanfish profiles |\n",
    "|TS | Thermosalinograph data |\n",
    "|XB | XBT or XCTD profiles |\n",
    "|TE | Data from TESAC messages on GTS |\n",
    "|SM | Sea-mammals |\n",
    "|HF | High Frequency Radar |\n",
    "|SD | Saildrone |\n",
    "|VA | Vessel mounted ADCP |\n",
    "|XX | Unknown |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "*** \n",
    "To find the updated catalog of possible codes for data sources (`data types` in documentation) please check the <a href=\"https://archimer.ifremer.fr/doc/00324/43494/\" target=\"_blank\">Product User Manual</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b style=\"margin-right: 2em\">CHALLENGE</b> Do you find in there the feature types of <a href=\"#platform_selected\">the platform</a> we were looking at in the platform section?\n",
    "    \n",
    "*** \n",
    "In the end the platform we are checking is a:\n",
    "* Profiler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is the full list but; which ones are actually available in this product/dataset/collection?<br> `Run the next cell` to discover them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_collection_info['data_type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, How many of each? `Run the next cells`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = [{\n",
    "    'code':code,\n",
    "    'platforms': {'nplatforms': len(files.groupby('platform_code')),'files': {'nfiles': len(files), 'features(s)': [{'code':ftype, 'nfiles': len(files.groupby('data_type').get_group(code).groupby('file_type').get_group(ftype)), 'nplatforms': len(files.groupby('data_type').get_group(code).groupby('platform_code'))} for ftype in files[files['data_type']==code]['file_type'].unique().tolist()]}}\n",
    "} for code,files in targeted_collection_info.groupby(['data_type'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IPython.display.HTML(json2html.convert(data_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too much info? Choose just one! `Run the next cell`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "code = 'PF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = [dtype for dtype in data_types if dtype['code'] == code]\n",
    "IPython.display.HTML(json2html.convert(selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Feature types` represents the shape of the data reported by a given platform data source. <br>So far the In Situ TAC distinguishes 4 feature types: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| code | description |\n",
    "| ------- | ------- |\n",
    "|TS | Time Serie |\n",
    "|PR | Profile |\n",
    "|TV | Grided data - High Frequency Radar total velocity fields |\n",
    "|RV | Grided data - High Frequency Radar radial velocity fields |\n",
    "|WS | Wave spectra |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "*** \n",
    "To find the updated catalog of possible codes for feature types (`file types` in documentation) please check the <a href=\"https://archimer.ifremer.fr/doc/00324/43494/\" target=\"_blank\">Product User Manual</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b style=\"margin-right: 2em\">CHALLENGE</b>Do you find in there the feature types of <a href=\"#platform_selected\">the platform</a> we were looking at in the platform section?\n",
    "    \n",
    "*** \n",
    "* Profiles (vertical measurements along the water column) of certain oceanographic variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is the full list but; which ones are actually available in this product/dataset/collection?<br> `Run the next cell`to know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_collection_info['file_type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, How many of each? `Run the next cells`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_types = [{\n",
    "    'code':code,\n",
    "    'platforms': {'nplatforms': len(files.groupby('platform_code')),'files': {'nfiles': len(files), 'sources(s)': [{'code':dtype, 'nfiles': len(files.groupby('file_type').get_group(code).groupby('data_type').get_group(dtype)), 'nplatforms': len(files.groupby('file_type').get_group(code).groupby('data_type').get_group(dtype).groupby('platform_code'))} for dtype in files[files['file_type']==code]['data_type'].unique().tolist()]}}\n",
    "} for code,files in targeted_collection_info.groupby(['file_type'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.HTML(json2html.convert(file_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "`parameters` represents the oceanographic variables measured by the platform and therefore present in its files. <br>So Far the In Situ TAC distinguishes the next ones (zoom with the -|+ controls if you do not see it properly): `run the next cell`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IPython.display.IFrame('https://archimer.ifremer.fr/doc/00422/53381/72333.pdf', width='100%', height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b>\n",
    "    \n",
    "*** \n",
    "To find the updated catalog of parameters please check <a href=\"https://archimer.ifremer.fr/doc/00422/53381/\" target=\"_blank\">this</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b style=\"margin-right: 2em\">CHALLENGE</b> Do you find in there the feature types of <a href=\"#platform_selected\">the platform</a> we were looking at in the platform section?\n",
    "\n",
    "*** \n",
    "In the end the platform we are checking is a profiler reporting:\n",
    "* Profiles of Temperature, Salinity and Oxygen variables along the water column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is the full list but; which ones are actually available in this product/dataset collection? `Run the next cell`and discover it!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = [param for param in list(set(sum([parameter.split(' ') for parameter in targeted_collection_info['parameters'].tolist()],[]))) if '_' not in param and param not in ['DEPH', 'PRES'] and param != '']\n",
    "parameter_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, How many of each? `Run the next cells`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{\n",
    "    'code':code,\n",
    "    'platforms':{\n",
    "        'nplatforms': len(targeted_collection_info[targeted_collection_info['parameters'].str.contains(code)].groupby('platform_code')),\n",
    "        'files':{\n",
    "            'nfiles': len(targeted_collection_info[targeted_collection_info['parameters'].str.contains(code)]), \n",
    "            'feature(s)': [{'code': ftype, 'nplatforms': len(targeted_collection_info[targeted_collection_info['parameters'].str.contains(code)].groupby('file_type').get_group(ftype).groupby('platform_code')), 'nfiles':len(targeted_collection_info[targeted_collection_info['parameters'].str.contains(code)].groupby('file_type').get_group(ftype)),'sources(s)': [{'code': dtype, 'nplatforms' : len(targeted_collection_info[targeted_collection_info['parameters'].str.contains(code)].groupby('file_type').get_group(ftype).groupby('data_type').get_group(dtype).groupby('platform_code')) ,'nfiles': len(targeted_collection_info[targeted_collection_info['parameters'].str.contains(code)].groupby('file_type').get_group(ftype).groupby('data_type').get_group(dtype))} for dtype in targeted_collection_info[targeted_collection_info['parameters'].str.contains(code)][targeted_collection_info['file_type']==ftype]['data_type'].unique().tolist()]} for ftype in targeted_collection_info[targeted_collection_info['parameters'].str.contains(code)]['file_type'].unique().tolist()]\n",
    "        }\n",
    "    }\n",
    "} for code in parameter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IPython.display.HTML(json2html.convert(parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too much info? Choose one! `Run the next cells`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "code = 'TEMP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = [param for param in parameters if param['code'] == code]\n",
    "IPython.display.HTML(json2html.convert(selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Providers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any Situ NRT products/datasets collections are composed by the files reported by a network of platforms located in the area. It is interesting always to know who are procuring these platforms and to aknowledge them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's `run the next cell` to know how many *known* providers are contributting to this product/dataset collection with files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers_list = list(set(sum([str(provider).split(' ') for provider in targeted_collection_info['institution_edmo_code'].tolist() if str(provider).isdigit()],[])))\n",
    "providers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not clear at all, right? These numbers are identifiers provided by [SeaDatanet]('https://www.seadatanet.org/'). <br>\n",
    "Just check who is who by using SeaDataNet services: `run the next cell`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '850' #change it by any other!\n",
    "IPython.display.IFrame('https://edmo.seadatanet.org/report/'+code, width='100%', height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much are they contributting to the product/datasetcollection?<br>`Run the next cells` to discover it!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_collection_info['institution_edmo_code'] = ' ' +targeted_collection_info['institution_edmo_code'].str.strip()+ ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [{\n",
    "    'code':code,\n",
    "    'platforms':{\n",
    "        'nplatforms': len(targeted_collection_info[targeted_collection_info['institution_edmo_code'].str.contains(' '+code+' ', na=False)].groupby('platform_code').groups.keys()),\n",
    "        'files':{'nfiles': len(targeted_collection_info[targeted_collection_info['institution_edmo_code'].str.contains(' '+code+' ', na=False)]), \n",
    "        'feature(s)': [{'code': ftype, 'nplatforms':len(targeted_collection_info[targeted_collection_info['institution_edmo_code'].str.contains(' '+code+' ', na=False)].groupby('file_type').get_group(ftype).groupby('platform_code')), 'nfiles':len(targeted_collection_info[targeted_collection_info['institution_edmo_code'].str.contains(' '+code+' ', na=False)].groupby('file_type').get_group(ftype)),'sources(s)': [{'code': dtype, 'nplatforms': len(targeted_collection_info[targeted_collection_info['institution_edmo_code'].str.contains(' '+code+' ', na=False)].groupby('file_type').get_group(ftype).groupby('data_type').get_group(dtype).groupby('platform_code')), 'nfiles': len(targeted_collection_info[targeted_collection_info['institution_edmo_code'].str.contains(' '+code+' ', na=False)].groupby('file_type').get_group(ftype).groupby('data_type').get_group(dtype))} for dtype in targeted_collection_info[targeted_collection_info['institution_edmo_code'].str.contains(' '+code+' ', na=False)][targeted_collection_info['file_type']==ftype]['data_type'].unique().tolist()]} for ftype in targeted_collection_info[targeted_collection_info['institution_edmo_code'].str.contains(' '+code+' ', na=False)]['file_type'].unique().tolist()]}\n",
    "    }\n",
    "} for code in providers_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.HTML(json2html.convert(providers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too much info? Choose one! `Run the next cells`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "code = '850'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = [provider for provider in providers if provider['code'] == code]\n",
    "IPython.display.HTML(json2html.convert(selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Wrap-up\n",
    "\n",
    "So far you should already know what to expect about this product/dataset/collection: platform network, file types, source types, parameters and providers.<br> `If you don't please ask us! it is the moment!`\n",
    "<br>In the next tutorial we will see how to retrieve the files comming from a certain platform, source, provider, matching a certain type of file or/and containing certain parameter. Ready? Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Next tutorial\n",
    "\n",
    "_Click on the hyperlink below to continue the training_\n",
    "\n",
    "[**13-02-NearRealTtime-product-subsetting-download.ipynb**](13-02-NearRealTtime-product-subsetting-download.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
